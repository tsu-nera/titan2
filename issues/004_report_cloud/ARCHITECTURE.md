# アーキテクチャ設計書

## 目次

1. [問題定義](#問題定義)
2. [要件分析](#要件分析)
3. [技術選定プロセス](#技術選定プロセス)
4. [採用アーキテクチャ](#採用アーキテクチャ)
5. [代替案との比較](#代替案との比較)
6. [コスト分析](#コスト分析)
7. [セキュリティ設計](#セキュリティ設計)
8. [スケーラビリティ](#スケーラビリティ)
9. [将来の拡張性](#将来の拡張性)

---

## 問題定義

### 現状の課題

```
[課題1] モビリティの欠如
- 脳波分析にPCが必須
- 外出先で結果確認できない

[課題2] 手動オペレーション
- Google Drive → ローカルダウンロード
- WSL起動 → コマンド実行
- 計測のたびに同じ作業

[課題3] データ管理
- CSVファイルが巨大（256MB）
- Gitには不向き
- ストレージ圧迫
```

### ユーザー要望

```
✅ スマホから分析結果閲覧
✅ 全15指標 + グラフ（issue 003同等）
✅ 2-5分の処理時間は許容
✅ 完全無料で実現
✅ Webブラウザで閲覧
❌ CSVデータをGitHubにcommitしたくない
```

---

## 要件分析

### 機能要件

| ID | 要件 | 優先度 | 備考 |
|----|------|--------|------|
| FR-01 | スマホからレポート閲覧 | 必須 | Webブラウザまたはアプリ |
| FR-02 | 全15指標の分析実行 | 必須 | MNE-Python必須 |
| FR-03 | グラフ画像15枚生成 | 必須 | Matplotlib使用 |
| FR-04 | 手動トリガー | 必須 | 自動実行は不要 |
| FR-05 | 過去レポート閲覧 | 推奨 | 履歴管理 |
| FR-06 | Google Drive連携 | 必須 | CSV取得 |

### 非機能要件

| ID | 要件 | 目標値 | 優先度 |
|----|------|--------|--------|
| NFR-01 | 処理時間 | 5分以内 | 必須 |
| NFR-02 | コスト | 0円/月 | 必須 |
| NFR-03 | メモリ | 4GB以上 | 必須（MNE-Python要件） |
| NFR-04 | 可用性 | 99%以上 | 推奨 |
| NFR-05 | セキュリティ | 個人データ保護 | 必須 |
| NFR-06 | インフラ管理 | 最小限 | 推奨 |

### 制約条件

```
技術的制約:
- MNE-Pythonが動作する環境必須
- メモリ: 4GB以上
- Python 3.11以上

運用制約:
- 無料枠内で実現
- サーバー管理を避ける
- 既存コード（issue 003）を最大限再利用

データ制約:
- CSVファイル: 97-256MB
- GitHubリポジトリに含めない
- Google Driveに保存
```

---

## 技術選定プロセス

### 評価軸

1. **実行環境**: MNE-Pythonが動作するか
2. **コスト**: 無料枠の範囲内か
3. **メモリ**: 4GB以上確保できるか
4. **自動化**: 手動トリガー可能か
5. **閲覧性**: スマホから見やすいか
6. **管理コスト**: インフラ管理の複雑さ
7. **データ管理**: CSV除外可能か

### 候補技術の洗い出し

以下7つのアプローチを検討:

1. Jupyter Notebook系（Google Colab等）
2. BIツール（Looker Studio等）
3. データパイプライン（Zapier等）
4. クラウドノートブック（SageMaker等）
5. サーバーレス分析（Streamlit Cloud等）
6. **GitHub Actions + Google Drive連携** ⭐
7. ローカル実行 + クラウド同期

---

## 採用アーキテクチャ

### 選定結果: GitHub Actions + Google Drive 連携

```
[Mind Monitor]
    ↓ CSV保存
[Google Drive]
    ↓ 手動トリガー
[スマホ: GitHub Mobile] workflow_dispatch
    ↓
[GitHub Actions]
    ├─ Drive API: 最新CSV取得
    ├─ Python分析実行
    │   └─ generate_report.py（issue 003）
    └─ Git commit: レポートのみ
    ↓
[GitHub Repository]
    └─ reports/YYYYMMDD_HHMMSS/
        ├─ REPORT.md
        └─ img/*.png
    ↓
[スマホ: GitHub] ブラウザでMarkdown閲覧
```

### 技術スタック詳細

#### 実行基盤

```yaml
プラットフォーム: GitHub Actions
OS: Ubuntu 22.04 LTS
CPU: 2コア
メモリ: 7GB
ストレージ: 14GB SSD
実行時間制限: 6時間/ジョブ
無料枠: 月2,000分（privateリポジトリ）
```

#### ランタイム

```python
言語: Python 3.11
仮想環境: 既存（titan）

主要ライブラリ:
- mne==1.10              # 脳波解析
- numpy>=1.25            # 数値計算
- pandas>=2.0            # データ処理
- matplotlib>=3.7        # 可視化
- scipy>=1.11            # 科学計算
- google-auth>=2.23      # 新規追加
- google-api-python-client>=2.100  # 新規追加
```

#### データフロー

```
入力:
  Google Drive → CSV（97-256MB）

処理:
  1. CSVダウンロード（30秒）
  2. データロード・前処理（1分）
  3. MNE解析（2-3分）
  4. グラフ生成15枚（1分）
  5. Markdown生成（10秒）

出力:
  GitHub → reports/
    ├─ REPORT.md（約170行）
    └─ img/*.png（15枚、合計5-10MB）

合計時間: 4-7分
```

---

## 代替案との比較

### 1. Google Colab（Jupyter Notebook）

**アーキテクチャ:**
```
スマホ → Colab（ブラウザ） → CSV upload → 実行 → 結果表示
```

**メリット:**
- GPU/TPU無料利用（今回不要）
- 対話的分析可能
- Google Drive統合済み
- メモリ12GB

**デメリット:**
- ❌ 手動実行必須（自動化は有料）
- ❌ 90分アイドルで切断
- ❌ レポート履歴管理が煩雑

**評価: ⭐⭐⭐**（手動オペレーションが残る）

---

### 2. Cloud Functions（GCP/AWS Lambda）

**アーキテクチャ:**
```
スマホ → Webフォーム → HTTP POST → Cloud Function → Drive API → 分析 → 結果返却
```

**メリット:**
- リアルタイム実行
- HTTPトリガー
- スケーラビリティ高

**デメリット:**
- ⚠️ 有料（月$5-10）
- 複雑な設定（VPC、IAM等）
- 実行時間制限（GCP: 9分、AWS: 15分）

**評価: ⭐⭐⭐⭐**（コスト要件を満たさず）

---

### 3. Streamlit Cloud

**アーキテクチャ:**
```
スマホ → Streamlitアプリ → CSV upload → 分析 → インタラクティブ表示
```

**メリット:**
- Pythonコード直接デプロイ
- インタラクティブUI
- 無料枠あり

**デメリット:**
- ❌ メモリ制限: 1GB（MNE-Pythonには不足）
- ❌ CPU制限: 弱い
- ❌ 長時間処理に不向き

**評価: ⭐⭐**（メモリ要件を満たさず）

---

### 4. Looker Studio（BIツール）

**アーキテクチャ:**
```
CSV → Looker Studio → ダッシュボード作成 → 閲覧
```

**メリット:**
- 完全無料
- ノーコード
- スマホ対応

**デメリット:**
- ❌ MNE-Pythonの高度分析不可
- ❌ Fmθ、Hilbert変換等未対応
- ❌ カスタム指標の限界

**評価: ⭐**（機能要件を満たさず）

---

### 5. Databricks Community Edition

**アーキテクチャ:**
```
CSV → Databricks Notebook → Spark分析 → 結果保存
```

**メリット:**
- 無料枠あり
- 大規模データ向け

**デメリット:**
- ⚠️ Spark学習コスト高
- 今回のデータサイズには過剰
- UI複雑

**評価: ⭐⭐**（オーバーキル）

---

### 6. GitHub Actions（採用案）

**アーキテクチャ:**
```
スマホ → GitHub Mobile → workflow_dispatch → Actions実行 → Git commit → 閲覧
```

**メリット:**
- ✅ 完全無料（月2000分）
- ✅ メモリ7GB（MNE-Python対応）
- ✅ Git統合（履歴管理）
- ✅ インフラ管理不要
- ✅ 既存コード100%再利用
- ✅ CSV除外可能

**デメリット:**
- ⚠️ 起動に30秒程度
- ⚠️ HTTPトリガー不可（workflow_dispatchのみ）

**評価: ⭐⭐⭐⭐⭐**（全要件を満たす）

---

### 7. ローカル実行 + クラウド同期

**アーキテクチャ:**
```
Google Drive → Syncthing → ローカルPC（cron） → Syncthing → スマホ閲覧
```

**メリット:**
- 既存環境そのまま
- コスト0円

**デメリット:**
- ❌ PC起動が必須
- ❌ 課題解決せず

**評価: ⭐**（要件を満たさず）

---

## 比較表

| 手段 | 無料 | 自動化 | メモリ | MNE対応 | CSV除外 | スマホ閲覧 | 管理コスト | 総合 |
|------|------|--------|--------|---------|---------|------------|------------|------|
| **GitHub Actions** | ✅ | ✅ | 7GB | ✅ | ✅ | ✅ | 低 | ⭐⭐⭐⭐⭐ |
| Google Colab | ✅ | ❌ | 12GB | ✅ | ✅ | ⚠️ | 低 | ⭐⭐⭐ |
| Cloud Functions | ❌ | ✅ | 設定次第 | ✅ | ✅ | ✅ | 中 | ⭐⭐⭐⭐ |
| Streamlit Cloud | ✅ | ✅ | 1GB | ❌ | ✅ | ✅ | 低 | ⭐⭐ |
| Looker Studio | ✅ | ✅ | N/A | ❌ | ✅ | ✅ | 低 | ⭐ |
| Databricks | ⚠️ | ✅ | 大 | ✅ | ✅ | ⚠️ | 高 | ⭐⭐ |
| ローカル同期 | ✅ | ⚠️ | 十分 | ✅ | ✅ | ❌ | 低 | ⭐ |

---

## コスト分析

### GitHub Actions無料枠

```
無料枠（private リポジトリ）:
- 実行時間: 2,000分/月
- ストレージ: 500MB
- 転送: 1GB/月

1回の分析:
- 実行時間: 5分
- ストレージ: 10MB（レポート + 画像）
- 転送: 256MB（CSV DL）+ 10MB（commit）

月間可能回数:
- 実行時間: 2000分 ÷ 5分 = 400回
- ストレージ: 500MB ÷ 10MB = 50世代（古いもの削除で管理）
- 転送: 1000MB ÷ 266MB ≈ 3-4回

ボトルネック: 転送量（1GB/月）
```

### 転送量対策

**問題**: CSV 256MB × 4回 = 1GB（上限）

**解決策1**: CSV圧縮
```
gzip圧縮: 256MB → 約50MB（圧縮率80%）
可能回数: 1000MB ÷ 60MB ≈ 16回/月
```

**解決策2**: Drive API cache
```
同じCSVを再ダウンロードしない
Etagでファイル更新検知
```

**解決策3**: Public リポジトリ化
```
無料枠: 実行時間 2,000分/月（同じ）
無料枠: ストレージ制限なし
無料枠: 転送制限なし

デメリット: レポート内容が公開される
対処: 個人情報を含まないことを確認
```

**推奨**: 解決策1（圧縮）+ 解決策2（キャッシュ）

### Google Drive API

```
無料枠:
- リクエスト: 1,000,000回/日
- ストレージ: 15GB（Googleアカウント全体）

1回の分析:
- リクエスト: 2回（検索 + ダウンロード）

月間可能回数: 実質無制限
コスト: 0円
```

### 総コスト

```
月額: 0円
年額: 0円

想定使用量（1日2回 × 30日 = 60回/月）:
- GitHub Actions: 300分/月（15%使用）
- 転送量: 圧縮後 3.6GB/月（無料枠超過 → Public化検討）
- Google Drive API: 120リクエスト/月（0.01%使用）

結論: 完全無料で運用可能
```

---

## セキュリティ設計

### 脅威モデル

| 脅威 | リスク | 対策 |
|------|--------|------|
| 認証情報漏洩 | 高 | GitHub Secrets使用 |
| CSVデータ漏洩 | 中 | Gitから除外、Drive権限管理 |
| レポート公開 | 低 | Privateリポジトリ |
| サービスアカウント悪用 | 中 | 最小権限、定期キーローテーション |

### セキュリティ対策

#### 1. 認証情報管理

```yaml
GitHub Secrets:
  GDRIVE_CREDENTIALS: サービスアカウントJSON
  GDRIVE_FOLDER_ID: フォルダID

特性:
  - 暗号化保存
  - リポジトリログに表示されない
  - Actions実行時のみ環境変数として利用
  - Forkされたリポジトリには複製されない
```

#### 2. 最小権限の原則

```
サービスアカウント権限:
  ✅ 特定フォルダの閲覧のみ
  ❌ 編集権限なし
  ❌ Drive全体へのアクセスなし
  ❌ 他のGCPサービスへのアクセスなし
```

#### 3. データ保護

```
CSV（個人データ含む）:
  - Gitにcommitしない（.gitignore）
  - GitHub Actions実行後、一時ファイル削除
  - Google Drive上で手動管理

レポート（匿名化データ）:
  - Gitにcommit OK
  - 個人を特定できる情報を含まない
```

#### 4. 監査ログ

```
GitHub Actions:
  - 実行履歴90日保持
  - 誰が、いつ実行したか記録
  - エラーログ保存

Google Cloud:
  - APIアクセスログ記録
  - 定期的に確認（推奨）
```

---

## スケーラビリティ

### 現状の制約

```
処理能力:
  - 1ジョブ: 6時間まで
  - 並列実行: 20ジョブ（無料枠）

データサイズ:
  - 現状: 256MB（30分セッション）
  - 想定最大: 500MB（1時間セッション）
  - GitHub Actions対応範囲: 数GB

ユーザー数:
  - 現状: 1人
  - 拡張: 複数ユーザー対応可能（フォルダ分け）
```

### スケールアウト戦略

#### シナリオ1: 長時間セッション（2時間以上）

**問題**: 処理時間増加（10分以上）

**対策**:
```python
# セグメント分割処理
1. CSVを30分単位で分割
2. 各セグメントを並列処理
3. 結果を統合

実装例:
  matrix strategy（GitHub Actions）
  並列度: 4セグメント同時
  処理時間: 1/4に短縮
```

#### シナリオ2: 複数ユーザー

**問題**: フォルダ管理、レポート混在

**対策**:
```yaml
ディレクトリ構造:
  reports/
    user1/
      20251104/
    user2/
      20251104/

workflow_dispatch入力:
  user_id: ユーザー識別子
```

#### シナリオ3: 転送量枯渇

**対策**: Public リポジトリ化（転送量無制限）

---

## 将来の拡張性

### Phase 7以降の拡張案

#### 1. GitHub Pages化

**概要**: 静的サイト生成でより見やすいUI

```
アーキテクチャ:
  Actions → Markdown → Jekyll/Hugo → GitHub Pages

メリット:
  - カスタムデザイン
  - ナビゲーション改善
  - グラフインタラクティブ化（Plotly.js）

追加コスト: 0円
実装工数: 2-3時間
```

#### 2. 通知機能

**概要**: 分析完了時にプッシュ通知

```
方法1: Slack連携
  Actions → Slack Webhook → 通知

方法2: LINE Bot
  Actions → LINE Messaging API → 通知

方法3: GitHub Notifications
  Actions → commit → GitHub通知（標準機能）

追加コスト: 0円
実装工数: 1時間
```

#### 3. データベース統合

**概要**: 過去データの集計・比較

```
アーキテクチャ:
  Actions → 分析 → SQLite/PostgreSQL → 統計グラフ

機能:
  - 週次/月次サマリー
  - 進捗トレンド
  - 統計検定

候補DB:
  - SQLite（GitHub内蔵）: 無料
  - Supabase（PostgreSQL）: 無料枠500MB

追加コスト: 0円
実装工数: 4-6時間
```

#### 4. 複数ファイル一括分析

**概要**: 週次まとめレポート

```
トリガー: 毎週日曜 0:00（schedule）
処理: Drive内の1週間分CSV取得 → 統合分析

レポート:
  - 週間平均スコア
  - 最良/最悪セッション比較
  - 時間帯別傾向

追加コスト: 0円
実装工数: 2-3時間
```

#### 5. リアルタイムダッシュボード

**概要**: ブラウザでインタラクティブ表示

```
技術:
  - Streamlit（別途ホスト）
  - GitHub からレポートデータ読み込み
  - Plotly.js でインタラクティブグラフ

ホスティング:
  - Streamlit Cloud: メモリ1GB（軽量版のみ）
  - Vercel: Next.js + JSON API

追加コスト: 0円
実装工数: 6-8時間
```

#### 6. Mobile App

**概要**: ネイティブアプリ

```
技術:
  - React Native / Flutter
  - GitHub API連携
  - オフライン閲覧

追加コスト: Apple Developer ($99/年)
実装工数: 20時間以上（フルスクラッチ）
```

---

## 技術的負債の管理

### 既知の制限事項

1. **転送量制限（1GB/月）**
   - 対処予定: CSV圧縮実装（Phase 2）

2. **レポート履歴の肥大化**
   - 対処予定: 90日以上前の自動削除スクリプト

3. **エラーハンドリング不足**
   - 対処予定: Phase 5で網羅的テスト

### メンテナンス計画

```
月次:
  - GitHub Actions実行ログ確認
  - Google Drive容量確認

四半期:
  - 依存ライブラリ更新（security patch）
  - Actions実行時間分析

年次:
  - サービスアカウントキーローテーション
  - アーキテクチャ見直し
```

---

## まとめ

### 採用理由

GitHub Actions + Google Drive 連携を選定した理由:

1. ✅ **全要件を満たす**（唯一の候補）
2. ✅ **完全無料**（月2000分枠内）
3. ✅ **既存資産活用**（issue 003コード再利用）
4. ✅ **インフラ管理不要**（サーバーレス）
5. ✅ **履歴管理自動**（Git統合）
6. ✅ **拡張性高**（将来の機能追加容易）

### トレードオフ

受け入れた制約:
- 起動に30秒〜1分（許容範囲）
- HTTPトリガー不可（手動実行で十分）
- 転送量制限（圧縮で対処）

### 次のアクション

1. [SETUP_GDRIVE.md](SETUP_GDRIVE.md) でGoogle Cloud設定
2. Phase 2でDrive連携スクリプト実装
3. Phase 3でGitHub Actions ワークフロー作成

---

**作成日**: 2025-11-04
**最終更新**: 2025-11-04
**関連ドキュメント**: [ISSUE.md](ISSUE.md), [SETUP_GDRIVE.md](SETUP_GDRIVE.md)
