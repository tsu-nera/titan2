# Data Engineering: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„

## ç›®çš„
ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦³ç‚¹ã‹ã‚‰ã€Raw Dataç®¡ç†ã€ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŒ–ã€è¨­å®šç®¡ç†ã‚’æ”¹å–„ã—ã€ä¿å®ˆæ€§ã¨æ‹¡å¼µæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

---

## ç¾çŠ¶ã®å•é¡Œç‚¹

### 1. Raw Dataã®é…ç½®ã¨ç®¡ç†

**å•é¡Œ**:
- `data/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ°¸ç¶šåŒ–ï¼ˆ97MBã€197MBï¼‰
- `.gitignore`ã§CSVã¯é™¤å¤–ã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’åœ§è¿«
- ã©ã®CSVãŒã©ã®ãƒ¬ãƒãƒ¼ãƒˆã«å¯¾å¿œã™ã‚‹ã‹è¿½è·¡å›°é›£
- `run_analysis.sh`ãŒæœ€æ–°CSVã‚’è‡ªå‹•é¸æŠï¼ˆæ„å›³ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã†å¯èƒ½æ€§ï¼‰
- å‰Šé™¤ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒä¸æ˜ç¢ºï¼ˆæ‰‹å‹•ç®¡ç†ãŒå¿…è¦ï¼‰

**ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ **:
```
titan2/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mindMonitor_2025-10-15--17-08-15_*.csv  (97MB)
â”‚   â””â”€â”€ mindMonitor_2025-10-31--16-04-01_*.csv  (197MB)
â”œâ”€â”€ issues/001_eeg_analysis/
â”‚   â”œâ”€â”€ run_analysis.sh          # data/ã‹ã‚‰æœ€æ–°CSVã‚’è‡ªå‹•é¸æŠ
â”‚   â””â”€â”€ REPORT.md
â””â”€â”€ .gitignore                   # *.csv ã¯é™¤å¤–æ¸ˆã¿
```

### 2. ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ‰±ã„

**å•é¡Œ**:
- `generate_report.py`å†…ã§f-stringé€£çµã«ã‚ˆã‚‹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆ64-215è¡Œç›®ï¼‰
- ãƒ¬ãƒãƒ¼ãƒˆæ§‹é€ ã®å¤‰æ›´ãŒPythonã‚³ãƒ¼ãƒ‰ã«ç›´çµ
- å¤šè¨€èªå¯¾å¿œã‚„ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå›°é›£
- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ›´æ™‚ã«Pythonã‚³ãƒ¼ãƒ‰ã‚’ç·¨é›†ã™ã‚‹å¿…è¦
- DRYåŸå‰‡é•åï¼ˆè¤‡æ•°issueã§åŒã˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯ã‚’é‡è¤‡ï¼‰

**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰**:
```python
# generate_report.py (64-215è¡Œç›®)
def generate_markdown_report(data_path, output_dir, results):
    report = f"""# Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«**: `{data_path.name}`

---

## 1. ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
...
"""
    # 150è¡Œä»¥ä¸Šã®f-stringé€£çµ
```

### 3. è¨­å®šã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç®¡ç†

**å•é¡Œ**:
- é–¾å€¤ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚³ãƒ¼ãƒ‰å†…ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå›°é›£
- å®Ÿé¨“çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´ã®ãŸã³ã«ã‚³ãƒ¼ãƒ‰ä¿®æ­£ãŒå¿…è¦

**ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å€¤ã®ä¾‹**:
```python
# generate_report.py (132-141è¡Œç›®)
if 'ãƒªãƒ©ãƒƒã‚¯ã‚¹' in ratio_name:
    level = 'ã¨ã¦ã‚‚é«˜ã„' if avg_value > 2.0 else 'é«˜ã„' if avg_value > 1.0 else 'æ™®é€š'
elif 'é›†ä¸­' in ratio_name:
    level = 'ã¨ã¦ã‚‚é«˜ã„' if avg_value > 2.0 else 'é«˜ã„' if avg_value > 1.0 else 'æ™®é€š'
elif 'ç‘æƒ³' in ratio_name:
    level = 'æ·±ã„' if avg_value > 1.5 else 'ä¸­ç¨‹åº¦' if avg_value > 0.8 else 'æµ…ã„'

# generate_report.py (176-183è¡Œç›®)
cv = stats['å¤‰å‹•ä¿‚æ•° (%)']
if cv < 2:
    stability = 'éå¸¸ã«å®‰å®š'
elif cv < 5:
    stability = 'å®‰å®š'
```

### 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ã®æ¬ å¦‚

**å•é¡Œ**:
- ã©ã®Raw CSVã‹ã‚‰ã©ã®ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚ŒãŸã‹è¨˜éŒ²ãŒãªã„
- éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¨ã®æ¯”è¼ƒã«å¿…è¦ãªæƒ…å ±ãŒæ•£é€¸
- ãƒ‡ãƒ¼ã‚¿å“è³ªã®å±¥æ­´ç®¡ç†ãŒã§ããªã„
- å†ç¾æ€§ã®ç¢ºä¿ãŒå›°é›£

### 5. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®ç„¡é§„

**å•é¡Œ**:
- ç´„300MBã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç´¯ç©ï¼ˆæ¯æ—¥ç‘æƒ³ã™ã‚‹ã¨æœˆ9GBï¼‰
- å®Ÿéš›ã«å¿…è¦ãªã®ã¯çµ±è¨ˆã‚µãƒãƒªãƒ¼ã®ã¿ï¼ˆæ•°KBï¼‰
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚„ã‚¯ãƒ­ãƒ¼ãƒ³æ™‚ã«ä¸è¦ãªãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹

---

## æ”¹å–„ææ¡ˆ

### ææ¡ˆ1: Raw Dataç®¡ç†ã®æ”¹å–„ï¼ˆå„ªå…ˆåº¦ï¼šæœ€é«˜ï¼‰

#### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®å¤‰æ›´

```
titan2/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # ä¸€æ™‚çš„ãªRawãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ†æå¾Œå‰Šé™¤ï¼‰
â”‚   â”‚   â””â”€â”€ session_20251031_160401/
â”‚   â”‚       â””â”€â”€ input.csv              # åˆ†æä¸­ã®ã¿å­˜åœ¨
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                     # å‡¦ç†æ¸ˆã¿è»½é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆæ°¸ç¶šåŒ–ï¼‰
â”‚   â”‚   â””â”€â”€ session_20251031_160401/
â”‚   â”‚       â”œâ”€â”€ metadata.json          # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã€ãƒãƒƒã‚·ãƒ¥å€¤
â”‚   â”‚       â”œâ”€â”€ summary_stats.json     # çµ±è¨ˆã‚µãƒãƒªãƒ¼ï¼ˆæ•°KBï¼‰
â”‚   â”‚       â””â”€â”€ key_metrics.parquet    # æ™‚ç³»åˆ—ã®é‡è¦æŒ‡æ¨™ï¼ˆè»½é‡ï¼‰
â”‚   â”‚
â”‚   â””â”€â”€ archive/                       # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šé•·æœŸä¿å­˜ç”¨
â”‚       â””â”€â”€ session_20251031.csv.gz    # åœ§ç¸®ç‰ˆ
```

#### DataManagerã‚¯ãƒ©ã‚¹ã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«**: `lib/data_manager.py` (æ–°è¦ä½œæˆ)

```python
from pathlib import Path
import shutil
import hashlib
import json
from datetime import datetime
import pandas as pd

class DataManager:
    """Raw CSVã®ä¸€æ™‚ç®¡ç†ã¨å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ã‚’æ‹…å½“"""

    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.raw_dir = self.project_root / 'data' / 'raw'
        self.processed_dir = self.project_root / 'data' / 'processed'
        self.archive_dir = self.project_root / 'data' / 'archive'

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        self.processed_dir.mkdir(parents=True, exist_ok=True)

    def register_raw_data(self, csv_path):
        """
        Raw CSVã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç™»éŒ²

        Returns:
            tuple: (session_id, temp_csv_path)
        """
        session_id = self._generate_session_id(csv_path)
        session_dir = self.raw_dir / session_id
        session_dir.mkdir(exist_ok=True)

        dest_path = session_dir / 'input.csv'
        shutil.copy(csv_path, dest_path)

        print(f'âœ“ Raw data registered: {session_id}')
        return session_id, dest_path

    def save_processed_data(self, session_id, csv_path, df, analysis_results):
        """
        å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜

        Parameters:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            csv_path: å…ƒã®CSVãƒ‘ã‚¹
            df: pandas DataFrame
            analysis_results: åˆ†æçµæœã®è¾æ›¸
        """
        processed_session = self.processed_dir / session_id
        processed_session.mkdir(exist_ok=True)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = {
            'session_id': session_id,
            'original_file': csv_path.name,
            'file_size_mb': round(csv_path.stat().st_size / (1024*1024), 2),
            'file_hash': self._calculate_hash(csv_path),
            'processed_at': datetime.now().isoformat(),
            'data_info': {
                'shape': str(df.shape),
                'start_time': str(df['TimeStamp'].min()),
                'end_time': str(df['TimeStamp'].max()),
                'duration_sec': (df['TimeStamp'].max() - df['TimeStamp'].min()).total_seconds()
            }
        }

        with open(processed_session / 'metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)

        # çµ±è¨ˆã‚µãƒãƒªãƒ¼ï¼ˆè»½é‡ï¼‰
        summary = {
            'total_score': analysis_results.get('total_score'),
            'band_statistics': analysis_results.get('band_statistics', {}).to_dict()
                if 'band_statistics' in analysis_results else {},
            'band_ratios_stats': analysis_results.get('band_ratios_stats', {}).to_dict()
                if 'band_ratios_stats' in analysis_results else {},
            'paf_summary': analysis_results.get('paf_summary', {}).to_dict()
                if 'paf_summary' in analysis_results else {},
        }

        with open(processed_session / 'summary_stats.json', 'w') as f:
            json.dump(summary, f, indent=2)

        # é‡è¦ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿å­˜ï¼ˆParquetå½¢å¼ã§åœ§ç¸®ï¼‰
        key_columns = ['TimeStamp', 'Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10',
                      'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10',
                      'Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10']

        if all(col in df.columns for col in key_columns):
            df[key_columns].to_parquet(
                processed_session / 'key_metrics.parquet',
                compression='gzip',
                index=False
            )

        print(f'âœ“ Processed data saved: {processed_session}')

    def cleanup_raw_data(self, session_id, confirm=True):
        """
        Raw CSVã‚’å‰Šé™¤ï¼ˆåˆ†æå®Œäº†å¾Œï¼‰

        Parameters:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            confirm: ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ã‹
        """
        session_dir = self.raw_dir / session_id

        if not session_dir.exists():
            print(f'âš  Raw data not found: {session_id}')
            return

        if confirm:
            print(f'ğŸ—‘ Deleting raw data: {session_dir}')

        shutil.rmtree(session_dir)
        print(f'âœ“ Raw data deleted: {session_id}')

    def archive_raw_data(self, session_id):
        """
        Raw CSVã‚’åœ§ç¸®ã—ã¦ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.archive_dir.mkdir(exist_ok=True)
        session_dir = self.raw_dir / session_id

        if not session_dir.exists():
            print(f'âš  Raw data not found: {session_id}')
            return

        import gzip
        raw_csv = session_dir / 'input.csv'
        archive_path = self.archive_dir / f'{session_id}.csv.gz'

        with open(raw_csv, 'rb') as f_in:
            with gzip.open(archive_path, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)

        print(f'âœ“ Archived: {archive_path}')

        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¾Œã«rawã‚’å‰Šé™¤
        self.cleanup_raw_data(session_id, confirm=False)

    def load_historical_data(self, limit=30):
        """
        éå»ã®å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æç”¨ï¼‰

        Returns:
            list: éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚µãƒãƒªãƒ¼ã®ãƒªã‚¹ãƒˆ
        """
        sessions = []

        for session_dir in sorted(self.processed_dir.iterdir(), reverse=True)[:limit]:
            if not session_dir.is_dir():
                continue

            metadata_path = session_dir / 'metadata.json'
            summary_path = session_dir / 'summary_stats.json'

            if metadata_path.exists() and summary_path.exists():
                with open(metadata_path) as f:
                    metadata = json.load(f)
                with open(summary_path) as f:
                    summary = json.load(f)

                sessions.append({
                    'session_id': session_dir.name,
                    'metadata': metadata,
                    'summary': summary
                })

        return sessions

    @staticmethod
    def _generate_session_id(csv_path):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ"""
        # mindMonitor_2025-10-31--16-04-01_*.csv -> session_20251031_160401
        name = csv_path.stem
        if 'mindMonitor_' in name:
            date_part = name.split('mindMonitor_')[1].split('_')[0]
            # 2025-10-31--16-04-01 -> 20251031_160401
            date_clean = date_part.replace('-', '').replace('--', '_').replace('-', '')[:15]
            return f'session_{date_clean}'
        else:
            return f'session_{datetime.now().strftime("%Y%m%d_%H%M%S")}'

    @staticmethod
    def _calculate_hash(file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®SHA256ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—ï¼ˆå…ˆé ­16æ–‡å­—ï¼‰"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b''):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()[:16]


def cleanup_all_raw_data(project_root, keep_latest=1):
    """
    ã™ã¹ã¦ã®Raw dataã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæ‰‹å‹•å®Ÿè¡Œç”¨ï¼‰

    Parameters:
        project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        keep_latest: æœ€æ–°Nä»¶ã¯ä¿æŒ
    """
    dm = DataManager(project_root)
    sessions = sorted(dm.raw_dir.iterdir(), reverse=True)

    for i, session_dir in enumerate(sessions):
        if i < keep_latest:
            print(f'â© Keeping: {session_dir.name}')
            continue

        if session_dir.is_dir():
            dm.cleanup_raw_data(session_dir.name, confirm=False)
```

#### generate_report.pyã®ä¿®æ­£

```python
# generate_report.py ã® run_full_analysis() ã«çµ±åˆ

from lib.data_manager import DataManager

def run_full_analysis(data_path, output_dir):
    # DataManageråˆæœŸåŒ–
    dm = DataManager(project_root)

    # Raw dataã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç™»éŒ²
    session_id, temp_csv_path = dm.register_raw_data(data_path)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
    df = load_mind_monitor_csv(temp_csv_path, quality_filter=False)

    # ... åˆ†æå‡¦ç† ...

    # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    dm.save_processed_data(session_id, data_path, df, results)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_markdown_report(data_path, output_dir, results)

    # Raw dataã‚’å‰Šé™¤
    dm.cleanup_raw_data(session_id)

    print(f'\nâœ“ Session: {session_id}')
    print(f'âœ“ Processed data: {dm.processed_dir / session_id}')
```

#### ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/cleanup_raw_data.sh` (æ–°è¦ä½œæˆ)

```bash
#!/bin/bash
# Raw dataã‚’ä¸€æ‹¬å‰Šé™¤

PROJECT_ROOT="$(cd "$(dirname "$0")/.." && pwd)"

echo "========================================="
echo "Raw Data Cleanup"
echo "========================================="
echo ""

RAW_DIR="$PROJECT_ROOT/data/raw"

if [ ! -d "$RAW_DIR" ]; then
    echo "âœ“ No raw data directory found"
    exit 0
fi

COUNT=$(find "$RAW_DIR" -mindepth 1 -maxdepth 1 -type d | wc -l)

if [ "$COUNT" -eq 0 ]; then
    echo "âœ“ No raw data sessions found"
    exit 0
fi

echo "Found $COUNT raw data session(s)"
echo ""

read -p "Delete all raw data? [y/N] " -n 1 -r
echo ""

if [[ $REPLY =~ ^[Yy]$ ]]; then
    rm -rf "$RAW_DIR"/*
    echo "âœ“ All raw data deleted"
else
    echo "âœ— Cancelled"
fi
```

---

### ææ¡ˆ2: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå„ªå…ˆåº¦ï¼šé«˜ï¼‰

#### Jinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å°å…¥

**å¿…è¦ãªè¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**:
```txt
# requirements.txt ã«è¿½åŠ 
jinja2>=3.1.0
```

**ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **:
```
titan2/
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ report_template.md           # åŸºæœ¬ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”‚   â”œâ”€â”€ report_template_en.md        # è‹±èªç‰ˆï¼ˆå°†æ¥ï¼‰
â”‚   â”œâ”€â”€ report_summary.md            # ã‚µãƒãƒªãƒ¼ç‰ˆ
â”‚   â””â”€â”€ components/                  # å†åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚       â”œâ”€â”€ executive_summary.md
â”‚       â”œâ”€â”€ band_statistics.md
â”‚       â””â”€â”€ data_quality.md
```

**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«**: `templates/report_template.md` (æ–°è¦ä½œæˆ)

```jinja2
# Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {{ generation_time }}
**ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«**: `{{ data_file }}`
**ã‚»ãƒƒã‚·ãƒ§ãƒ³ID**: {{ session_id }}

---

{% if executive_summary %}
## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

- **ç·åˆã‚¹ã‚³ã‚¢**: {{ executive_summary.total_score }}/100 {% if executive_summary.score_change %}({{ executive_summary.score_change }}){% endif %}
- **ã‚»ãƒƒã‚·ãƒ§ãƒ³è©•ä¾¡**: {{ executive_summary.evaluation }}
- **ä¸»è¦æŒ‡æ¨™**:
  - FmÎ¸: {{ executive_summary.frontal_theta_level }}
  - Alphaå®‰å®šæ€§: {{ executive_summary.alpha_stability_level }}
  - é›†ä¸­æŒç¶šåŠ›: {{ executive_summary.attention_span_level }}

{% if executive_summary.dashboard_img %}
![ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰](img/{{ executive_summary.dashboard_img }})
{% endif %}

---
{% endif %}

## 1. ãƒ‡ãƒ¼ã‚¿æ¦‚è¦

- **ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶**: {{ data_info.shape }}
- **è¨˜éŒ²æ™‚é–“**: {{ data_info.start_time }} ~ {{ data_info.end_time }}
- **è¨ˆæ¸¬æ™‚é–“**: {{ data_info.duration_sec|round(1) }} ç§’

{% if time_segments %}
## 2. æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ

{{ time_segments.stats_table|safe }}

### é›†ä¸­åº¦ã®æ™‚é–“æ¨ç§»

![æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ](img/{{ time_segments.plot_img }})

**ãƒ”ãƒ¼ã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: {{ time_segments.peak_time_range }}

---
{% endif %}

## {% if time_segments %}3{% else %}2{% endif %}. å‘¨æ³¢æ•°ãƒãƒ³ãƒ‰çµ±è¨ˆ

{{ band_statistics|safe }}

**å‘¨æ³¢æ•°ãƒãƒ³ãƒ‰ã®èª¬æ˜**:
- **Delta (0.5-4 Hz)**: æ·±ã„ç¡çœ 
- **Theta (4-8 Hz)**: ç‘æƒ³ã€å‰µé€ æ€§
- **Alpha (8-13 Hz)**: ãƒªãƒ©ãƒƒã‚¯ã‚¹ã€ç›®ã‚’é–‰ã˜ãŸçŠ¶æ…‹
- **Beta (13-30 Hz)**: é›†ä¸­ã€æ´»å‹•
- **Gamma (30-50 Hz)**: é«˜åº¦ãªèªçŸ¥å‡¦ç†

{% if band_power_img %}
## {% if time_segments %}4{% else %}3{% endif %}. ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼ã®æ™‚é–“æ¨ç§»

![ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼æ™‚ç³»åˆ—](img/{{ band_power_img }})

Alphaæ³¢ãŒé«˜ã„ã¨ãƒªãƒ©ãƒƒã‚¯ã‚¹çŠ¶æ…‹ã€Betaæ³¢ãŒé«˜ã„ã¨é›†ä¸­çŠ¶æ…‹ã‚’ç¤ºã—ã¾ã™ã€‚
{% endif %}

{% if psd_img %}
## {% if time_segments %}5{% else %}4{% endif %}. ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«å¯†åº¦ï¼ˆPSDï¼‰

![PSD](img/{{ psd_img }})

{% if psd_peaks %}
### å„ãƒãƒ³ãƒ‰ã®ãƒ”ãƒ¼ã‚¯å‘¨æ³¢æ•°

{{ psd_peaks|safe }}
{% endif %}
{% endif %}

{% if spectrogram_img %}
## {% if time_segments %}6{% else %}5{% endif %}. ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ 

![ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ](img/{{ spectrogram_img }})

æ™‚é–“ã¨ã¨ã‚‚ã«å‘¨æ³¢æ•°åˆ†å¸ƒãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™ã€‚
{% endif %}

{% if band_ratios_img %}
## {% if time_segments %}7{% else %}6{% endif %}. è„³æ³¢æŒ‡æ¨™ï¼ˆãƒãƒ³ãƒ‰æ¯”ç‡ï¼‰

![ãƒãƒ³ãƒ‰æ¯”ç‡](img/{{ band_ratios_img }})

{% if band_ratios_stats %}
### æŒ‡æ¨™ã‚µãƒãƒªãƒ¼

{{ band_ratios_stats|safe }}

### ã‚»ãƒƒã‚·ãƒ§ãƒ³è©•ä¾¡

{% for evaluation in session_evaluations %}
- **{{ evaluation.name }}**: {{ evaluation.value }} ({{ evaluation.level }})
{% endfor %}
{% endif %}

{% if spike_analysis %}
### ãƒ‡ãƒ¼ã‚¿å“è³ªï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯åˆ†æï¼‰

{{ spike_analysis|safe }}
{% endif %}
{% endif %}

{% if paf_img %}
## {% if time_segments %}8{% else %}7{% endif %}. Peak Alpha Frequency (PAF) åˆ†æ

![PAF](img/{{ paf_img }})

{% if paf_summary %}
### ãƒãƒ£ãƒãƒ«åˆ¥PAF

{{ paf_summary|safe }}
{% endif %}

{% if iaf %}
**Individual Alpha Frequency (IAF)**: {{ iaf.value|round(2) }} Â± {{ iaf.std|round(2) }} Hz
{% endif %}

{% if paf_time_img %}
### PAFã®æ™‚é–“çš„å¤‰åŒ–

![PAFæ™‚é–“æ¨ç§»](img/{{ paf_time_img }})

{% if paf_time_stats %}
#### PAFçµ±è¨ˆ

{% for key, value in paf_time_stats.items() %}
- **{{ key }}**: {{ value|round(2) }}
{% endfor %}

**PAFå®‰å®šæ€§è©•ä¾¡**: {{ paf_stability }}
{% endif %}
{% endif %}
{% endif %}

{% if historical_comparison %}
## {% if time_segments %}9{% else %}8{% endif %}. éå»ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ

### ãƒˆãƒ¬ãƒ³ãƒ‰

- **å‰æ—¥æ¯”**: {{ historical_comparison.yesterday_change }}
- **é€±å¹³å‡**: {{ historical_comparison.week_average }}
- **ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢**: {{ historical_comparison.best_score }} ({{ historical_comparison.best_date }})

![ã‚¹ã‚³ã‚¢ãƒˆãƒ¬ãƒ³ãƒ‰](img/{{ historical_comparison.trend_img }})
{% endif %}

{% if action_advice %}
---

## ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ãƒ‰ãƒã‚¤ã‚¹

### ä»Šå›ã®å¼·ã¿

{% for strength in action_advice.strengths %}
- {{ strength }}
{% endfor %}

### æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ

{% for improvement in action_advice.improvements %}
- {{ improvement }}
{% endfor %}

### æ¬¡å›ã¸ã®ææ¡ˆ

{% for suggestion in action_advice.suggestions %}
- {{ suggestion }}
{% endfor %}
{% endif %}

---

## ã¾ã¨ã‚

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€Museãƒ˜ãƒƒãƒ‰ãƒãƒ³ãƒ‰ã§å–å¾—ã—ãŸè„³æ³¢ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çš„ãªåˆ†æã‚’è¡Œã„ã¾ã—ãŸã€‚

### åˆ†æå†…å®¹

1. **ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿**: CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
2. **åŸºæœ¬çµ±è¨ˆ**: å„å‘¨æ³¢æ•°ãƒãƒ³ãƒ‰ã®ç‰¹æ€§ã‚’æŠŠæ¡
3. **ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼**: æ™‚é–“çµŒéã«ä¼´ã†å„ãƒãƒ³ãƒ‰ã®å¤‰åŒ–ã‚’è¿½è·¡
4. **å‘¨æ³¢æ•°è§£æ**: PSDã¨ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã§å‘¨æ³¢æ•°ç‰¹æ€§ã‚’è©³ç´°åˆ†æ
5. **æŒ‡æ¨™åˆ†æ**: ãƒªãƒ©ãƒƒã‚¯ã‚¹åº¦ã€é›†ä¸­åº¦ã€ç‘æƒ³æ·±åº¦ã®æ•°å€¤åŒ–
6. **PAFåˆ†æ**: Peak Alpha Frequencyã®æ¸¬å®šã¨æ™‚é–“å¤‰åŒ–ã®è¿½è·¡

---

**ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `generate_report.py`
**åˆ†æã‚¨ãƒ³ã‚¸ãƒ³**: MNE-Python, pandas, matplotlib
**ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**: lib/eeg.py
**ã‚»ãƒƒã‚·ãƒ§ãƒ³ID**: {{ session_id }}
**ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥**: {{ data_hash }}
```

#### ReportGeneratorã‚¯ãƒ©ã‚¹ã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«**: `lib/report_generator.py` (æ–°è¦ä½œæˆ)

```python
from jinja2 import Environment, FileSystemLoader
from pathlib import Path
import pandas as pd

class ReportGenerator:
    """Jinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

    def __init__(self, template_dir=None):
        if template_dir is None:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰templatesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
            template_dir = Path(__file__).parents[1] / 'templates'

        self.template_dir = Path(template_dir)
        self.env = Environment(
            loader=FileSystemLoader(str(self.template_dir)),
            trim_blocks=True,
            lstrip_blocks=True
        )

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ«ã‚¿ç™»éŒ²
        self.env.filters['to_markdown'] = self._df_to_markdown

    def generate(self, template_name, output_path, context):
        """
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Parameters:
            template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆä¾‹: 'report_template.md'ï¼‰
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            context: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã™ãƒ‡ãƒ¼ã‚¿ï¼ˆè¾æ›¸ï¼‰
        """
        template = self.env.get_template(template_name)

        # DataFrameã‚’Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›
        context = self._prepare_context(context)

        content = template.render(**context)

        output_path = Path(output_path)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f'âœ“ Report generated: {output_path}')

    def _prepare_context(self, context):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ï¼ˆDataFrameã‚’Markdownã«å¤‰æ›ï¼‰"""
        prepared = {}

        for key, value in context.items():
            if isinstance(value, pd.DataFrame):
                prepared[key] = self._df_to_markdown(value)
            elif isinstance(value, dict):
                # è¾æ›¸ã®ä¸­ã®DataFrameã‚‚å¤‰æ›
                prepared[key] = {
                    k: self._df_to_markdown(v) if isinstance(v, pd.DataFrame) else v
                    for k, v in value.items()
                }
            else:
                prepared[key] = value

        return prepared

    @staticmethod
    def _df_to_markdown(df, **kwargs):
        """DataFrameã‚’Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›"""
        if not isinstance(df, pd.DataFrame):
            return df

        default_kwargs = {'index': False, 'floatfmt': '.4f'}
        default_kwargs.update(kwargs)

        return df.to_markdown(**default_kwargs)
```

#### generate_report.pyã®ä¿®æ­£

```python
# generate_report.py

from lib.report_generator import ReportGenerator

def generate_markdown_report(data_path, output_dir, results, session_id):
    """
    ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
    """
    report_path = output_dir / 'REPORT.md'
    print(f'ç”Ÿæˆä¸­: ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ -> {report_path}')

    # ReportGeneratoråˆæœŸåŒ–
    generator = ReportGenerator()

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    context = {
        'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'data_file': data_path.name,
        'session_id': session_id,
        'data_hash': results.get('data_hash', 'N/A'),
        'data_info': results.get('data_info', {}),
        'band_statistics': results.get('band_statistics'),
        'band_power_img': results.get('band_power_img'),
        'psd_img': results.get('psd_img'),
        'psd_peaks': results.get('psd_peaks'),
        'spectrogram_img': results.get('spectrogram_img'),
        'band_ratios_img': results.get('band_ratios_img'),
        'band_ratios_stats': results.get('band_ratios_stats'),
        'spike_analysis': results.get('spike_analysis'),
        'paf_img': results.get('paf_img'),
        'paf_summary': results.get('paf_summary'),
        'iaf': results.get('iaf'),
        'paf_time_img': results.get('paf_time_img'),
        'paf_time_stats': results.get('paf_time_stats'),
        'paf_stability': results.get('paf_stability', 'ä¸æ˜'),

        # æ–°æ©Ÿèƒ½ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
        'executive_summary': results.get('executive_summary'),
        'time_segments': results.get('time_segments'),
        'historical_comparison': results.get('historical_comparison'),
        'action_advice': results.get('action_advice'),

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©•ä¾¡ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‹ã‚‰æŠ½å‡ºï¼‰
        'session_evaluations': _build_session_evaluations(results)
    }

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generator.generate('report_template.md', report_path, context)

    print(f'âœ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}')


def _build_session_evaluations(results):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³è©•ä¾¡ã‚’æ§‹ç¯‰ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°åŒ–ï¼‰"""
    evaluations = []

    if 'band_ratios_stats' not in results:
        return evaluations

    for _, row in results['band_ratios_stats'].iterrows():
        ratio_name = row['æŒ‡æ¨™']
        avg_value = row['å¹³å‡å€¤']

        if 'ãƒªãƒ©ãƒƒã‚¯ã‚¹' in ratio_name:
            level = 'ã¨ã¦ã‚‚é«˜ã„' if avg_value > 2.0 else 'é«˜ã„' if avg_value > 1.0 else 'æ™®é€š'
        elif 'é›†ä¸­' in ratio_name:
            level = 'ã¨ã¦ã‚‚é«˜ã„' if avg_value > 2.0 else 'é«˜ã„' if avg_value > 1.0 else 'æ™®é€š'
        elif 'ç‘æƒ³' in ratio_name:
            level = 'æ·±ã„' if avg_value > 1.5 else 'ä¸­ç¨‹åº¦' if avg_value > 0.8 else 'æµ…ã„'
        else:
            level = 'ä¸æ˜'

        evaluations.append({
            'name': ratio_name,
            'value': f'{avg_value:.3f}',
            'level': level
        })

    return evaluations
```

---

### ææ¡ˆ3: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¤–éƒ¨åŒ–ï¼ˆå„ªå…ˆåº¦ï¼šä¸­ï¼‰

#### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å°å…¥

**å¿…è¦ãªè¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**:
```txt
# requirements.txt ã«è¿½åŠ 
pyyaml>=6.0
```

**ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **:
```
titan2/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ analysis_config.yaml      # åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ scoring_config.yaml       # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è¨­å®š
â”‚   â””â”€â”€ visualization_config.yaml # å¯è¦–åŒ–è¨­å®š
```

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: `config/analysis_config.yaml` (æ–°è¦ä½œæˆ)

```yaml
# åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

analysis:
  # æ™‚ç³»åˆ—åˆ†æ
  segment_duration_minutes: 5
  window_size_seconds: 4
  overlap_ratio: 0.5

  # å‘¨æ³¢æ•°ãƒãƒ³ãƒ‰å®šç¾©ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰
  frequency_bands:
    delta: [0.5, 4]
    theta: [4, 8]
    alpha: [8, 13]
    beta: [13, 30]
    gamma: [30, 50]
    frontal_theta: [6, 7]  # FmÎ¸å°‚ç”¨

  # ãƒ‡ãƒ¼ã‚¿å“è³ª
  quality_filter:
    enabled: false
    min_signal_quality: 0.8
    remove_outliers: true
    outlier_std_threshold: 3.0

# PSDè¨ˆç®—
psd:
  method: 'welch'
  fmin: 0.5
  fmax: 50
  n_fft: 1024
  n_overlap: 512

# ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ 
spectrogram:
  method: 'morlet'
  freqs_min: 1
  freqs_max: 50
  n_cycles: 7
```

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: `config/scoring_config.yaml` (æ–°è¦ä½œæˆ)

```yaml
# ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è¨­å®š

scoring:
  # ç·åˆã‚¹ã‚³ã‚¢ã®é‡ã¿é…åˆ†
  weights:
    frontal_theta: 0.30      # FmÎ¸ãƒ‘ãƒ¯ãƒ¼
    alpha_stability: 0.20    # Alphaå®‰å®šæ€§
    attention_span: 0.20     # æ³¨æ„æŒç¶šåŠ›
    beta_alpha_ratio: 0.15   # ç·Šå¼µåº¦ã®ä½ã•
    data_quality: 0.15       # ãƒ‡ãƒ¼ã‚¿å“è³ª

# è©•ä¾¡é–¾å€¤
thresholds:
  # ãƒªãƒ©ãƒƒã‚¯ã‚¹åº¦ (Î±/Î²)
  relaxation_ratio:
    very_high: 2.0
    high: 1.0
    normal: 0.5

  # é›†ä¸­åº¦ (Î²/Î¸)
  concentration_ratio:
    very_high: 2.0
    high: 1.0
    normal: 0.5

  # ç‘æƒ³æ·±åº¦ (Î¸/Î±)
  meditation_depth:
    deep: 1.5
    moderate: 0.8
    shallow: 0.3

  # PAFå®‰å®šæ€§ï¼ˆå¤‰å‹•ä¿‚æ•°ï¼‰
  paf_stability:
    very_stable: 2
    stable: 5
    moderate: 10
    unstable: 999

# ç·åˆã‚¹ã‚³ã‚¢è©•ä¾¡ãƒ¬ãƒ™ãƒ«
score_levels:
  excellent: 80
  good: 60
  fair: 40
  poor: 0
```

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: `config/visualization_config.yaml` (æ–°è¦ä½œæˆ)

```yaml
# å¯è¦–åŒ–è¨­å®š

visualization:
  # å›³ã®åŸºæœ¬è¨­å®š
  figure:
    dpi: 300
    width: 12
    height: 8
    style: 'seaborn-v0_8-darkgrid'

  # ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ 
  colors:
    delta: '#1f77b4'
    theta: '#ff7f0e'
    alpha: '#2ca02c'
    beta: '#d62728'
    gamma: '#9467bd'

  # ãƒ•ã‚©ãƒ³ãƒˆ
  font:
    family: 'sans-serif'
    size: 12
    japanese: 'Noto Sans CJK JP'

  # å‡ºåŠ›å½¢å¼
  output:
    format: 'png'
    transparent: false
    bbox_inches: 'tight'
```

#### ConfigLoaderã‚¯ãƒ©ã‚¹ã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«**: `lib/config_loader.py` (æ–°è¦ä½œæˆ)

```python
import yaml
from pathlib import Path
from typing import Any, Dict

class ConfigLoader:
    """YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ç®¡ç†"""

    def __init__(self, config_dir=None):
        if config_dir is None:
            config_dir = Path(__file__).parents[1] / 'config'

        self.config_dir = Path(config_dir)
        self._cache = {}

    def load(self, config_name: str) -> Dict[str, Any]:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿

        Parameters:
            config_name: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.yamlæ‹¡å¼µå­ãªã—ï¼‰

        Returns:
            è¨­å®šè¾æ›¸
        """
        if config_name in self._cache:
            return self._cache[config_name]

        config_path = self.config_dir / f'{config_name}.yaml'

        if not config_path.exists():
            raise FileNotFoundError(f'Config file not found: {config_path}')

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        self._cache[config_name] = config
        return config

    def get(self, config_name: str, *keys, default=None):
        """
        ãƒã‚¹ãƒˆã•ã‚ŒãŸè¨­å®šå€¤ã‚’å–å¾—

        Parameters:
            config_name: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å
            *keys: ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚­ãƒ¼
            default: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        Examples:
            >>> config.get('analysis_config', 'analysis', 'segment_duration_minutes')
            5
        """
        config = self.load(config_name)

        value = config
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default

        return value


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_config_loader = None

def get_config_loader():
    """ConfigLoaderã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _config_loader
    if _config_loader is None:
        _config_loader = ConfigLoader()
    return _config_loader


def load_config(config_name: str) -> Dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    return get_config_loader().load(config_name)


def get_config_value(config_name: str, *keys, default=None):
    """è¨­å®šå€¤ã‚’å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    return get_config_loader().get(config_name, *keys, default=default)
```

#### ä½¿ç”¨ä¾‹

```python
# generate_report.py

from lib.config_loader import load_config, get_config_value

def run_full_analysis(data_path, output_dir):
    # è¨­å®šèª­ã¿è¾¼ã¿
    analysis_config = load_config('analysis_config')
    scoring_config = load_config('scoring_config')

    # è¨­å®šå€¤ã®å–å¾—
    segment_duration = analysis_config['analysis']['segment_duration_minutes']
    fmtheta_band = analysis_config['analysis']['frequency_bands']['frontal_theta']

    # ã¾ãŸã¯ç›´æ¥å–å¾—
    weights = get_config_value('scoring_config', 'scoring', 'weights')
    relaxation_thresholds = get_config_value('scoring_config', 'thresholds', 'relaxation_ratio')

    # è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ã§ä½¿ç”¨
    avg_value = 1.5
    if avg_value > relaxation_thresholds['very_high']:
        level = 'ã¨ã¦ã‚‚é«˜ã„'
    elif avg_value > relaxation_thresholds['high']:
        level = 'é«˜ã„'
    elif avg_value > relaxation_thresholds['normal']:
        level = 'æ™®é€š'
    else:
        level = 'ä½ã„'
```

---

### ææ¡ˆ4: run_analysis.shã®æ”¹å–„ï¼ˆå„ªå…ˆåº¦ï¼šä¸­ï¼‰

#### æ”¹å–„ç‚¹

**ç¾çŠ¶ã®å•é¡Œ**:
- æœ€æ–°CSVã‚’è‡ªå‹•é¸æŠï¼ˆæ„å›³ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã†å¯èƒ½æ€§ï¼‰
- åˆ†æå¾Œã®Raw dataå‰Šé™¤ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒãªã„

**æ”¹å–„ç‰ˆ**: `issues/003_improve_daily_report/run_analysis.sh`

```bash
#!/bin/bash
#
# Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åŸºæœ¬åˆ†æ å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹å–„ç‰ˆï¼‰
#
# Usage:
#   ./run_analysis.sh [CSV_FILE_PATH] [OPTIONS]
#
# Options:
#   --keep-raw      Raw CSVã‚’å‰Šé™¤ã—ãªã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å‰Šé™¤ï¼‰
#   --archive       Raw CSVã‚’åœ§ç¸®ã—ã¦ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
#

set -e

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¸ã®ç›¸å¯¾ãƒ‘ã‚¹
PROJECT_ROOT="$(cd "$(dirname "$0")/../.." && pwd)"
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³è§£æ
KEEP_RAW=false
ARCHIVE_RAW=false

while [[ $# -gt 0 ]]; do
    case $1 in
        --keep-raw)
            KEEP_RAW=true
            shift
            ;;
        --archive)
            ARCHIVE_RAW=true
            shift
            ;;
        -*)
            echo "Unknown option: $1"
            exit 1
            ;;
        *)
            CSV_FILE="$1"
            shift
            ;;
    esac
done

# ä»®æƒ³ç’°å¢ƒã®ãƒã‚§ãƒƒã‚¯
if [ ! -d "$PROJECT_ROOT/titan" ]; then
    echo "ã‚¨ãƒ©ãƒ¼: ä»®æƒ³ç’°å¢ƒ 'titan' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    echo "ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„:"
    echo "  cd $PROJECT_ROOT"
    echo "  python3 -m venv titan"
    echo "  source titan/bin/activate"
    echo "  pip install -r requirements.txt"
    exit 1
fi

# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
source "$PROJECT_ROOT/titan/bin/activate"

# CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å–å¾—
if [ -z "$CSV_FILE" ]; then
    # å¼•æ•°ãªã—ã®å ´åˆã€dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æœ€æ–°CSVã‚’è¡¨ç¤ºã—ã¦ç¢ºèª
    LATEST_CSV=$(find "$PROJECT_ROOT/data" -name "mindMonitor_*.csv" -type f -printf "%T@ %p\n" | sort -rn | head -1 | cut -d' ' -f2-)

    if [ -z "$LATEST_CSV" ]; then
        echo "ã‚¨ãƒ©ãƒ¼: data/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        echo ""
        echo "Usage: $0 [CSV_FILE_PATH] [--keep-raw] [--archive]"
        exit 1
    fi

    echo "æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«: $(basename "$LATEST_CSV")"
    read -p "ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã‹? [Y/n] " -n 1 -r
    echo ""

    if [[ $REPLY =~ ^[Nn]$ ]]; then
        echo "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ"
        exit 0
    fi

    CSV_FILE="$LATEST_CSV"
else
    if [ ! -f "$CSV_FILE" ]; then
        echo "ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $CSV_FILE"
        exit 1
    fi
fi

# åˆ†æå®Ÿè¡Œ
echo "============================================================"
echo "Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åŸºæœ¬åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™"
echo "============================================================"
echo ""
echo "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: $(basename "$CSV_FILE")"
echo "å‡ºåŠ›å…ˆ: $SCRIPT_DIR"
echo "Raw dataå‰Šé™¤: $([ "$KEEP_RAW" = true ] && echo "ã—ãªã„" || echo "ã™ã‚‹")"
echo "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: $([ "$ARCHIVE_RAW" = true ] && echo "ã™ã‚‹" || echo "ã—ãªã„")"
echo ""

cd "$SCRIPT_DIR"

# Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¸¡ã™
PYTHON_ARGS="--data \"$CSV_FILE\" --output ."
[ "$KEEP_RAW" = true ] && PYTHON_ARGS="$PYTHON_ARGS --keep-raw"
[ "$ARCHIVE_RAW" = true ] && PYTHON_ARGS="$PYTHON_ARGS --archive"

eval python generate_report.py $PYTHON_ARGS

echo ""
echo "============================================================"
echo "åˆ†æå®Œäº†!"
echo "============================================================"
echo ""
echo "ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:"
echo "  - REPORT.md (ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ)"
echo "  - img/*.png (ã‚°ãƒ©ãƒ•ç”»åƒ)"
echo ""

if [ "$KEEP_RAW" = false ]; then
    echo "âœ“ Raw CSVã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ"
fi

if [ "$ARCHIVE_RAW" = true ]; then
    echo "âœ“ Raw CSVã¯ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚Œã¾ã—ãŸ: data/archive/"
fi

echo ""
echo "ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª:"
echo "  cat REPORT.md"
echo ""
```

#### generate_report.pyã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è¿½åŠ 

```python
# generate_report.py

def main():
    parser = argparse.ArgumentParser(
        description='Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰'
    )
    parser.add_argument(
        '--data',
        type=Path,
        required=True,
        help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    parser.add_argument(
        '--output',
        type=Path,
        default=Path(__file__).parent,
        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰'
    )
    parser.add_argument(
        '--keep-raw',
        action='store_true',
        help='Raw CSVã‚’å‰Šé™¤ã—ãªã„'
    )
    parser.add_argument(
        '--archive',
        action='store_true',
        help='Raw CSVã‚’åœ§ç¸®ã—ã¦ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–'
    )

    args = parser.parse_args()

    # ... (ä»¥ä¸‹çœç•¥)
```

---

## å®Ÿè£…é †åº

### Phase 1: åŸºç›¤æ•´å‚™ï¼ˆWeek 1ï¼‰

1. **DataManagerã‚¯ãƒ©ã‚¹ã®å®Ÿè£…**
   - [ ] `lib/data_manager.py` ä½œæˆ
   - [ ] `data/raw/`, `data/processed/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
   - [ ] `generate_report.py` ã«DataManagerçµ±åˆ
   - [ ] ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

2. **ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
   - [ ] `scripts/cleanup_raw_data.sh` ä½œæˆ
   - [ ] å®Ÿè¡Œæ¨©é™ä»˜ä¸: `chmod +x scripts/cleanup_raw_data.sh`

3. **æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œ**
   - [ ] ç¾åœ¨ã®`data/*.csv`ã‚’æ‰‹å‹•å‰Šé™¤
   - [ ] æ–°ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

### Phase 2: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŒ–ï¼ˆWeek 2ï¼‰

4. **Jinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ**
   - [ ] `templates/report_template.md` ä½œæˆ
   - [ ] `requirements.txt` ã«jinja2è¿½åŠ 
   - [ ] pip install

5. **ReportGeneratorã‚¯ãƒ©ã‚¹ã®å®Ÿè£…**
   - [ ] `lib/report_generator.py` ä½œæˆ
   - [ ] `generate_report.py` ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã«å¤‰æ›´
   - [ ] ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

### Phase 3: è¨­å®šå¤–éƒ¨åŒ–ï¼ˆWeek 3ï¼‰

6. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ**
   - [ ] `config/analysis_config.yaml` ä½œæˆ
   - [ ] `config/scoring_config.yaml` ä½œæˆ
   - [ ] `config/visualization_config.yaml` ä½œæˆ
   - [ ] `requirements.txt` ã«pyyamlè¿½åŠ 

7. **ConfigLoaderã‚¯ãƒ©ã‚¹ã®å®Ÿè£…**
   - [ ] `lib/config_loader.py` ä½œæˆ
   - [ ] `generate_report.py` ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
   - [ ] ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸé–¾å€¤ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ç§»è¡Œ

### Phase 4: çµ±åˆã¨ãƒ†ã‚¹ãƒˆï¼ˆWeek 4ï¼‰

8. **run_analysis.shã®æ”¹å–„**
   - [ ] ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ ï¼ˆ--keep-raw, --archiveï¼‰
   - [ ] CSVãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã®ç¢ºèªæ©Ÿèƒ½

9. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°**
   - [ ] README.mdæ›´æ–°
   - [ ] ä½¿ç”¨ä¾‹ã®è¿½åŠ 

10. **æœ€çµ‚ãƒ†ã‚¹ãƒˆ**
    - [ ] å®Œå…¨ãªåˆ†æãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    - [ ] æ—¢å­˜issue (001, 002) ã®å‹•ä½œç¢ºèª

---

## æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### 1. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®å‰Šæ¸›
- **ç¾çŠ¶**: æœˆé–“ç´„9GBï¼ˆæ¯æ—¥30åˆ†ç‘æƒ³æƒ³å®šï¼‰
- **æ”¹å–„å¾Œ**: æœˆé–“ç´„10MBï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚µãƒãƒªãƒ¼ã®ã¿ï¼‰
- **å‰Šæ¸›ç‡**: 99.9%

### 2. ä¿å®ˆæ€§ã®å‘ä¸Š
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ†é›¢ã«ã‚ˆã‚Šãƒ¬ãƒãƒ¼ãƒˆæ§‹é€ ã®å¤‰æ›´ãŒå®¹æ˜“
- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒç°¡å˜
- ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§å‘ä¸Šï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã¨è¡¨ç¤ºã®åˆ†é›¢ï¼‰

### 3. ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ã®ç¢ºä¿
- ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å®Œå…¨ãªè¿½è·¡
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
- éå»ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒæ©Ÿèƒ½ã®åŸºç›¤

### 4. æ‹¡å¼µæ€§ã®å‘ä¸Š
- å¤šè¨€èªå¯¾å¿œãŒå®¹æ˜“ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¿½åŠ ã®ã¿ï¼‰
- æ–°æŒ‡æ¨™ã®è¿½åŠ ãŒç°¡å˜ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ï¼‰
- ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã®è¿½åŠ ï¼ˆHTML, PDFãªã©ï¼‰

---

## å‚è€ƒ: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ

```
# ç¾çŠ¶ï¼ˆRaw CSVã®ã¿ä¿å­˜ï¼‰
mindMonitor_2025-10-31.csv          197MB

# æ”¹å–„å¾Œï¼ˆå‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
session_20251031_160401/
  â”œâ”€â”€ metadata.json                  2KB
  â”œâ”€â”€ summary_stats.json             5KB
  â””â”€â”€ key_metrics.parquet            50KB
åˆè¨ˆ:                                 57KB

åœ§ç¸®ç‡: 99.97%
```

---

## å‚™è€ƒ

- æ—¢å­˜ã®`issues/001_eeg_analysis`ã¨`issues/002_optics_analysis`ã«ã‚‚åŒæ§˜ã®æ”¹å–„ã‚’é©ç”¨å¯èƒ½
- Jupyter Notebookã¨ã®çµ±åˆã‚‚æ¤œè¨ï¼ˆ`.ipynb`ã§ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–åˆ†æï¼‰
- CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸ã®çµ„ã¿è¾¼ã¿ï¼ˆè‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼‰
